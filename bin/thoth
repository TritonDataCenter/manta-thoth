#!/usr/bin/env node

/*
 * Copyright (c) 2013, Joyent, Inc. All rights reserved.
 */

var mod_ctype = require('ctype');
var mod_path = require('path');
var mod_fs = require('fs');
var util = require('util');
var mod_crypto = require('crypto');
var mod_bunyan = require('bunyan');
var mod_restify = require('restify');
var mod_manta = require('manta');
var mod_zlib = require('zlib');
var mod_child = require('child_process');

var sprintf = require('sprintf').sprintf;

var handlers = {};

var thoth = {
	version: 1,
	hashlen: 32,
	path: '/' + (process.env.THOTH_USER ? process.env.THOTH_USER :
	    process.env.MANTA_USER) + '/stor/thoth',
	analyzers: 'analyzers',
	logs: 'logs',
	log: 'log',
	verbose: true,
	cmds: [
		{ token: 'upload', params: '[file]',
		    usage: 'upload the specified core or crash dump' },
		{ token: 'info', params: '[dump]',
		    usage: 'print information about the specified dump(s)' },
		{ token: 'ls', params: '[[dump]]',
		    usage: 'list dumps matching the specification' },
		{ token: 'object', params: '[dump]', disconnected: true,
		    usage: 'print object name for specified dump(s)' },
		{ token: 'report', params: '[dump] [agg]',
		    usage: 'report on dumps matching the specification' },
		{ token: 'set', params: '[dump] [prop] [val]',
		    usage: 'set prop to val for the specified dump(s)' },
		{ token: 'unset', params: '[dump] [prop]',
		    usage: 'unset prop for the specified dump(s)' },
		{ token: 'ticket', params: '[dump] [ticket]',
		    usage: 'set ticket for the specified dump(s)' },
		{ token: 'unticket', params: '[dump]',
		    usage: 'unset ticket for the specified dump(s)' },
		{ token: 'analyze', params: '[dump] [analyzer]',
		    usage: 'analyze the specified dump(s)' },
		{ token: 'analyzer', params: '[analyzer]',
		    usage: 'add the named analyzer from stdin' },
		{ token: 'analyzers',
		    usage: 'list analyzers' },
		{ token: 'debug', params: '[dump]',
		    usage: 'debug the specified dump via mlogin and mdb' },
		{ token: 'logs',
		    usage: 'list logs for the past hour' }
	]
};

var status = function (msg)
{
	if (thoth.verbose)
		console.error('thoth: ' + msg);
}

var warn = function (msg)
{
	console.error('thoth: ' + msg);
}

var fatal = function (msg, code)
{
	var i, c = mod_path.basename(process.argv[1]);

	console.error(c + ': ' + msg);

	process.exit(code ? code : 1);
};

var usage = function (msg)
{
	var i, c = mod_path.basename(process.argv[1]);

	console.error(c + ': ' + msg);
        console.error('Usage: ' + c + ' [command] [params]\n');

	for (i = 0; i < thoth.cmds.length; i++) {
		var cmd = thoth.cmds[i].token + (thoth.cmds[i].params ?
		    (' ' + thoth.cmds[i].params) : '');

		console.error(sprintf('  %-26s %s',
		    cmd, thoth.cmds[i].usage));
        }

        process.exit(1);
};

var hms = function (ms)
{
	var seconds = Math.floor(ms / 1000);

	return (Math.floor((seconds / 3600)) + 'h' +
	    Math.floor(((seconds % 3600) / 60)) + 'm' +
	    (seconds % 60) + 's');
};

/*
 * To determine if the specified file is a core file, we need to read the
 * ELF headers and look at the type.  This routine will fail if it's not
 * an ELF file or not an ELF core file.
 */
var isCore = function (fd, sum)
{
	var width, endianness, hdr;
	var minsize = 8192, i;

	var err = function (msg) {
		if (thoth.crazyverbose) 
			warn('not an ELF file: ' + msg);
	};

	var int64 = function (val) {
		if (!(val instanceof Array))
			return (val);

		return ((val[0] << 32) + val[1]);
	};

	var constants = {
		EI_NIDENT: 16,
		EI_MAG0: 0,
		EI_MAG1: 1,
		EI_MAG2: 2,
		EI_MAG3: 3,
		EI_CLASS: 4,
		EI_DATA: 5,
		EI_VERSION: 6,
		EI_OSABI: 7,
		EI_ABIVERSION: 8,
		EI_PAD: 9,
		ELFMAG0: 0x7f,
		ELFMAG1: 'E'.charCodeAt(0),
		ELFMAG2: 'L'.charCodeAt(0),
		ELFMAG3: 'F'.charCodeAt(0),
		ELFMAG: '\177ELF',
		SELFMAG: 4,
		ELFCLASSNONE: 0,
		ELFCLASS32: 1,
		ELFCLASS64: 2,
		ELFCLASSNUM: 3,
		ELFDATANONE: 0,
		ELFDATA2LSB: 1,
		ELFDATA2MSB: 2,
		ELFDATANUM: 3,
		ET_NONE: 0,
		ET_REL: 1,
		ET_EXEC: 2,
		ET_DYN: 3,
		ET_CORE: 4,
		ET_NUM: 5,
		ET_LOOS: 0xfe00,
		ET_LOSUNW: 0xfeff,
		ET_SUNWPSEUDO: 0xfeff,
		ET_HISUNW: 0xfeff,
		ET_HIOS: 0xfeff,
		ET_LOPROC: 0xff00,
		ET_HIPROC: 0xffff,
		ET_LOPROC: 0xff00,
		ET_HIPROC: 0xffff,
		EM_NONE: 0,
		EM_M32: 1,
		EM_SPARC: 2,
		EM_386: 3,
		EM_68K: 4,
		EM_88K: 5,
		EM_486: 6,
		EM_860: 7,
		EM_MIPS: 8,
		EM_S370: 9,
		EM_MIPS_RS3_LE: 10,
		EM_RS6000: 11,
		EM_UNKNOWN12: 12,
		EM_UNKNOWN13: 13,
		EM_UNKNOWN14: 14,
		EM_PA_RISC: 15,
		EM_PARISC: 15,
		EM_nCUBE: 16,
		EM_VPP500: 17,
		EM_SPARC32PLUS: 18,
		EM_960: 19,
		EM_PPC: 20,
		EM_PPC64: 21,
		EM_S390: 22,
		EM_UNKNOWN22: 22,
		EM_UNKNOWN23: 23,
		EM_UNKNOWN24: 24,
		EM_UNKNOWN25: 25,
		EM_UNKNOWN26: 26,
		EM_UNKNOWN27: 27,
		EM_UNKNOWN28: 28,
		EM_UNKNOWN29: 29,
		EM_UNKNOWN30: 30,
		EM_UNKNOWN31: 31,
		EM_UNKNOWN32: 32,
		EM_UNKNOWN33: 33,
		EM_UNKNOWN34: 34,
		EM_UNKNOWN35: 35,
		EM_V800: 36,
		EM_FR20: 37,
		EM_RH32: 38,
		EM_RCE: 39,
		EM_ARM: 40,
		EM_ALPHA: 41,
		EM_SH: 42,
		EM_SPARCV9: 43,
		EM_TRICORE: 44,
		EM_ARC: 45,
		EM_H8_300: 46,
		EM_H8_300H: 47,
		EM_H8S: 48,
		EM_H8_500: 49,
		EM_IA_64: 50,
		EM_MIPS_X: 51,
		EM_COLDFIRE: 52,
		EM_68HC12: 53,
		EM_MMA: 54,
		EM_PCP: 55,
		EM_NCPU: 56,
		EM_NDR1: 57,
		EM_STARCORE: 58,
		EM_ME16: 59,
		EM_ST100: 60,
		EM_TINYJ: 61,
		EM_AMD64: 62,
		EM_X86_64: 62,
		EM_PDSP: 63,
		EM_UNKNOWN64: 64,
		EM_UNKNOWN65: 65,
		EM_FX66: 66,
		EM_ST9PLUS: 67,
		EM_ST7: 68,
		EM_68HC16: 69,
		EM_68HC11: 70,
		EM_68HC08: 71,
		EM_68HC05: 72,
		EM_SVX: 73,
		EM_ST19: 74,
		EM_VAX: 75,
		EM_CRIS: 76,
		EM_JAVELIN: 77,
		EM_FIREPATH: 78,
		EM_ZSP: 79,
		EM_MMIX: 80,
		EM_HUANY: 81,
		EM_PRISM: 82,
		EM_AVR: 83,
		EM_FR30: 84,
		EM_D10V: 85,
		EM_D30V: 86,
		EM_V850: 87,
		EM_M32R: 88,
		EM_MN10300: 89,
		EM_MN10200: 90,
		EM_PJ: 91,
		EM_OPENRISC: 92,
		EM_ARC_A5: 93,
		EM_XTENSA: 94,
		EM_NUM: 95,
		EV_NONE: 0,
		EV_CURRENT: 1,
		EV_NUM: 2,
		ELFOSABI_NONE: 0,
		ELFOSABI_SYSV: 0,
		ELFOSABI_HPUX: 1,
		ELFOSABI_NETBSD: 2,
		ELFOSABI_LINUX: 3,
		ELFOSABI_UNKNOWN4: 4,
		ELFOSABI_UNKNOWN5: 5,
		ELFOSABI_SOLARIS: 6,
		ELFOSABI_AIX: 7,
		ELFOSABI_IRIX: 8,
		ELFOSABI_FREEBSD: 9,
		ELFOSABI_TRU64: 10,
		ELFOSABI_MODESTO: 11,
		ELFOSABI_OPENBSD: 12,
		ELFOSABI_OPENVMS: 13,
		ELFOSABI_NSK: 14,
		ELFOSABI_AROS: 15,
		ELFOSABI_ARM: 97,
		ELFOSABI_STANDALONE: 255,
		EAV_SUNW_NONE: 0,
		EAV_SUNW_CURRENT: 1,
		EAV_SUNW_NUM: 2,
		PT_NULL: 0,
		PT_LOAD: 1,
		PT_DYNAMIC: 2,
		PT_INTERP: 3,
		PT_NOTE: 4,
		PT_SHLIB: 5,
		PT_PHDR: 6,
		PT_TLS: 7,
		PT_NUM: 8,
		PT_LOOS: 0x60000000,
		PT_SUNW_UNWIND: 0x6464e550,
		PT_SUNW_EH_FRAME: 0x6474e550,
		PT_GNU_EH_FRAME: 0x6474e550,
		PT_GNU_STACK: 0x6474e551,
		PT_GNU_RELRO: 0x6474e552,
		PT_LOSUNW: 0x6ffffffa,
		PT_SUNWBSS: 0x6ffffffa,
		PT_SUNWSTACK: 0x6ffffffb,
		PT_SUNWDTRACE: 0x6ffffffc,
		PT_SUNWCAP: 0x6ffffffd,
		PT_HISUNW: 0x6fffffff,
		PT_HIOS: 0x6fffffff,
		PT_LOPROC: 0x70000000,
		PT_HIPROC: 0x7fffffff,
		PF_R: 0x4,
		PF_W: 0x2,
		PF_X: 0x1,
		PF_MASKOS: 0x0ff00000,
		PF_MASKPROC: 0xf0000000,
		PF_SUNW_FAILURE: 0x00100000,
		PF_SUNW_KILLED: 0x00200000,
		PF_SUNW_SIGINFO: 0x00400000,
		PN_XNUM: 0xffff,
		SHT_NULL: 0,
		SHT_PROGBITS: 1,
		SHT_SYMTAB: 2,
		SHT_STRTAB: 3,
		SHT_RELA: 4,
		SHT_HASH: 5,
		SHT_DYNAMIC: 6,
		SHT_NOTE: 7,
		SHT_NOBITS: 8,
		SHT_REL: 9,
		SHT_SHLIB: 10,
		SHT_DYNSYM: 11,
		SHT_UNKNOWN12: 12,
		SHT_UNKNOWN13: 13,
		SHT_INIT_ARRAY: 14,
		SHT_FINI_ARRAY: 15,
		SHT_PREINIT_ARRAY: 16,
		SHT_GROUP: 17,
		SHT_SYMTAB_SHNDX: 18,
		SHT_NUM: 19,
		SHT_LOOS: 0x60000000,
		SHT_LOSUNW: 0x6fffffef,
		SHT_SUNW_capchain: 0x6fffffef,
		SHT_SUNW_capinfo: 0x6ffffff0,
		SHT_SUNW_symsort: 0x6ffffff1,
		SHT_SUNW_tlssort: 0x6ffffff2,
		SHT_SUNW_LDYNSYM: 0x6ffffff3,
		SHT_SUNW_dof: 0x6ffffff4,
		SHT_SUNW_cap: 0x6ffffff5,
		SHT_SUNW_SIGNATURE: 0x6ffffff6,
		SHT_SUNW_ANNOTATE: 0x6ffffff7,
		SHT_SUNW_DEBUGSTR: 0x6ffffff8,
		SHT_SUNW_DEBUG: 0x6ffffff9,
		SHT_SUNW_move: 0x6ffffffa,
		SHT_SUNW_COMDAT: 0x6ffffffb,
		SHT_SUNW_syminfo: 0x6ffffffc,
		SHT_SUNW_verdef: 0x6ffffffd,
		SHT_GNU_verdef: 0x6ffffffd,
		SHT_SUNW_verneed: 0x6ffffffe,
		SHT_GNU_verneed: 0x6ffffffe,
		SHT_SUNW_versym: 0x6fffffff,
		SHT_GNU_versym: 0x6fffffff,
		SHT_HISUNW: 0x6fffffff,
		SHT_HIOS: 0x6fffffff,
		SHT_GNU_ATTRIBUTES: 0x6ffffff5,
		SHT_GNU_HASH: 0x6ffffff6,
		SHT_GNU_LIBLIST: 0x6ffffff7,
		SHT_CHECKSUM: 0x6ffffff8,
		SHT_LOPROC: 0x70000000,
		SHT_HIPROC: 0x7fffffff,
		SHT_LOUSER: 0x80000000,
		SHT_HIUSER: 0xffffffff,
		SHF_WRITE: 0x01,
		SHF_ALLOC: 0x02,
		SHF_EXECINSTR: 0x04,
		SHF_MERGE: 0x10,
		SHF_STRINGS: 0x20,
		SHF_INFO_LINK: 0x40,
		SHF_LINK_ORDER: 0x80,
		SHF_OS_NONCONFORMING: 0x100,
		SHF_GROUP: 0x200,
		SHF_TLS: 0x400,
		SHF_MASKOS: 0x0ff00000,
		SHF_MASKPROC: 0xf0000000,
		SHN_UNDEF: 0,
		SHN_LORESERVE: 0xff00,
		SHN_LOPROC: 0xff00,
		SHN_HIPROC: 0xff1f,
		SHN_LOOS: 0xff20,
		SHN_LOSUNW: 0xff3f,
		SHN_SUNW_IGNORE: 0xff3f,
		SHN_HISUNW: 0xff3f,
		SHN_HIOS: 0xff3f,
		SHN_ABS: 0xfff1,
		SHN_COMMON: 0xfff2,
		SHN_XINDEX: 0xffff,
		SHN_HIRESERVE: 0xffff,
		STN_UNDEF: 0,
		STB_LOCAL: 0,
		STB_GLOBAL: 1,
		STB_WEAK: 2,
		STB_NUM: 3,
		STB_LOPROC: 13,
		STB_HIPROC: 15,
		STT_NOTYPE: 0,
		STT_OBJECT: 1,
		STT_FUNC: 2,
		STT_SECTION: 3,
		STT_FILE: 4,
		STT_COMMON: 5,
		STT_TLS: 6,
		STT_NUM: 7,
		STT_LOOS: 10,
		STT_HIOS: 12,
		STT_LOPROC: 13,
		STT_HIPROC: 15,
		STV_DEFAULT: 0,
		STV_INTERNAL: 1,
		STV_HIDDEN: 2,
		STV_PROTECTED: 3,
		STV_EXPORTED: 4,
		STV_SINGLETON: 5,
		STV_ELIMINATE: 6,
		STV_NUM: 7,
		GRP_COMDAT: 0x01,
		CAPINFO_NONE: 0,
		CAPINFO_CURRENT: 1,
		CAPINFO_NUM: 2,
		CAPCHAIN_NONE: 0,
		CAPCHAIN_CURRENT: 1,
		CAPCHAIN_NUM: 2,
		CAPINFO_SUNW_GLOB: 0xff,
		CA_SUNW_NULL: 0,
		CA_SUNW_HW_1: 1,
		CA_SUNW_SF_1: 2,
		CA_SUNW_HW_2: 3,
		CA_SUNW_PLAT: 4,
		CA_SUNW_MACH: 5,
		CA_SUNW_ID: 6,
		CA_SUNW_NUM: 7,
		SF1_SUNW_FPKNWN: 0x001,
		SF1_SUNW_FPUSED: 0x002,
		SF1_SUNW_ADDR32: 0x004,
		SF1_SUNW_MASK: 0x007,
		NT_PRSTATUS: 1,
		NT_PRFPREG: 2,
		NT_PRPSINFO: 3,
		NT_PRXREG: 4,
		NT_PLATFORM: 5,
		NT_AUXV: 6,
		NT_GWINDOWS: 7,
		NT_ASRS: 8,
		NT_LDT: 9,
		NT_PSTATUS: 10,
		NT_PSINFO: 13,
		NT_PRCRED: 14,
		NT_UTSNAME: 15,
		NT_LWPSTATUS: 16,
		NT_LWPSINFO: 17,
		NT_PRPRIV: 18,
		NT_PRPRIVINFO: 19,
		NT_CONTENT: 20,
		NT_ZONENAME: 21,
		NT_FDINFO: 22,
		NT_SPYMASTER: 23,
		NT_NUM: 23
	};

	var Elf_Ehdr = [
		{ e_ident: { type: 'char[' + constants.EI_NIDENT + ']' } },
		{ e_type: { type: 'Elf_Half' } },
		{ e_machine: { type: 'Elf_Half' } },
		{ e_version: { type: 'Elf_Word' } },
		{ e_entry: { type: 'Elf_Addr' } },
		{ e_phoff: { type: 'Elf_Off' } },
		{ e_shoff: { type: 'Elf_Off' } },
		{ e_flags: { type: 'Elf_Word' } },
		{ e_ehsize: { type: 'Elf_Half' } },
		{ e_phentsize: { type: 'Elf_Half' } },
		{ e_phnum: { type: 'Elf_Half' } },
		{ e_shentsize: { type: 'Elf_Half' } },
		{ e_shnum: { type: 'Elf_Half' } },
		{ e_shstrndx: { type: 'Elf_Half' } }
	];

	var Elf_Phdr32 = [
		{ p_type: { type: 'Elf_Word' } },
		{ p_offset: { type: 'Elf_Off' } },
		{ p_vaddr: { type: 'Elf_Addr' } },
		{ p_paddr: { type: 'Elf_Addr' } },
		{ p_filesz: { type: 'Elf_Size' } },
		{ p_memsz: { type: 'Elf_Size' } },
		{ p_flags: { type: 'Elf_Word' } },
		{ p_align: { type: 'Elf_Size' } }
	];

	var Elf_Phdr64 = [
		{ p_type: { type: 'Elf_Word' } },
		{ p_flags: { type: 'Elf_Word' } },
		{ p_offset: { type: 'Elf_Off' } },
		{ p_vaddr: { type: 'Elf_Addr' } },
		{ p_paddr: { type: 'Elf_Addr' } },
		{ p_filesz: { type: 'Elf_Size' } },
		{ p_memsz: { type: 'Elf_Size' } },
		{ p_align: { type: 'Elf_Size' } }
	];

	var Elf_Phdr;

	var parser = new mod_ctype.Parser({ endian: 'little' });
	var buffer = new Buffer(minsize);

	try {
		mod_fs.readSync(fd, buffer, 0, minsize, 0);
	} catch (err) {
		err('couldn\'t read ELF header');
		return (false);
	}

	var ehdr = parser.readData(Elf_Ehdr.slice(0, 1), buffer, 0);
	var hdr = ehdr.e_ident;

	for (i = 0; i < constants.SELFMAG; i++) {
		if (hdr[constants['EI_MAG' + i]] != constants['ELFMAG' + i]) {
			err('mismatch at magic ' + i);
			return (false);
		}
	}

	switch (hdr[constants.EI_CLASS]) {
	case constants.ELFCLASS32:
		width = '32';
		Elf_Phdr = Elf_Phdr32;
		break;
	case constants.ELFCLASS64:
		width = '64';
		Elf_Phdr = Elf_Phdr64;
		break;
	default:
		err('unknown class ' + hdr[constants.EI_CLASS]);
		return (false);
	}

	switch (hdr[constants.EI_DATA]) {
	case constants.ELFDATA2LSB:
		endianness = 'little';
		break;
	case constants.ELFDATA2MSB:
		endianness = 'big';
		break;
	default:
		err('unknown data class ' + hdr[constants.EI_DATA]);
		return (false);
	}
  
	parser = new mod_ctype.Parser({ endian: endianness });

	var types = {
		Elf_Addr: 'uint' + width + '_t',
		Elf_Off: 'uint' + width + '_t',
		Elf_Size: 'uint' + width + '_t',
		Elf_Half: 'uint16_t',
		Elf_Word: 'uint32_t',
		Elf_Sword: 'int32_t',
		Elf_Xword: 'uint64_t',
		Elf_Sxword: 'int64_t'
	};

	for (t in types)
		parser.typedef(t, types[t]);

	var ehdr = parser.readData(Elf_Ehdr, buffer, 0);

	if (ehdr.e_type != constants.ET_CORE)
		return (false);

	var phdrsz = ehdr.e_phentsize * ehdr.e_phnum;

	/*
	 * Now read the program headers
	 */
	var pbuffer = new Buffer(phdrsz);

	try {
		mod_fs.readSync(fd, pbuffer, 0, phdrsz, int64(ehdr.e_phoff));
	} catch (e) {
		err('couldn\'t read ' + phdrsz +
		    ' bytes of program headers at ' + int64(ehdr.e_phoff));
		return (false);
	}

	for (i = 0; i < ehdr.e_phnum; i++) {
		var notes, nsize, noffs;

		var phdr = parser.readData(Elf_Phdr, pbuffer,
		    i * ehdr.e_phentsize);

		sum.update(JSON.stringify(phdr));

		if (phdr.p_type != constants.PT_NOTE)
			continue;

		/*
		 * To hash a core dump, we hash the program headers and the
		 * note sections.  This contains information like the current
		 * machine and process state (including microstate accounting
		 * times) to assure that it's fully unique.
		 */
		noffs = int64(phdr.p_offset);
		nsize = int64(phdr.p_filesz);
		notes = new Buffer(nsize);

		try {
			mod_fs.readSync(fd, notes, 0, nsize, noffs);
		} catch (e) {
			err('couldn\'t read ' + nsize +
			    ' bytes of PT_NOTE at ' + noffs + ': ' +
			    util.inspect(e));
			return (false);
		}

		sum.update(notes);
	}

	return (true);
}

var isCrash = function (fd, sum)
{
	var parser = new mod_ctype.Parser({ endian: 'little' });
	var hdr, p;

	var minsize = 8192;
	var buffer = new Buffer(minsize);

	try {
		mod_fs.readSync(fd, buffer, 0, minsize, 0);
	} catch (err) {
		return (false);
	}

	var constants = {
		DUMP_MAGIC: 0xdefec8ed,
		DF_VALID: 0x00000001,
		DF_COMPLETE: 0x00000002,
		DF_LIVE: 0x00000004,
		DF_COMPRESSED: 0x00000008,
		DF_KERNEL: 0x00010000,
		DF_ALL: 0x00020000,
		DF_CURPROC: 0x00040000,
		DF_CONTENT: 0xffff0000
	};

	var utsname = [
		{ sysname: { type: 'char[257]' } },
		{ nodename: { type: 'char[257]' } },
		{ release: { type: 'char[257]' } },
		{ version: { type: 'char[257]' } },
		{ machine: { type: 'char[257]' } }
	];

	var dumphdr = [
		{ dump_magic: { type: 'uint32_t' } },
		{ dump_version: { type: 'uint32_t' } },
		{ dump_flags: { type: 'uint32_t' } },
		{ dump_wordsize: { type: 'uint32_t' } },
		{ dump_start: { type: 'offset_t' } },
		{ dump_ksyms: { type: 'offset_t' } },
		{ dump_pfn: { type: 'offset_t' } },
		{ dump_map: { type: 'offset_t' } },
		{ dump_data: { type: 'offset_t' } },
		{ dump_utsname: { type: 'struct utsname' } },
		{ dump_platform: { type: 'char[257]' } },
		{ dump_panicstring: { type: 'char[202]' } },
		{ dump_crashtime: { type: 'time_t' } },
		{ dump_pageshift: { type: 'int64_t' } },
		{ dump_pagesize: { type: 'int64_t' } },
		{ dump_hashmask: { type: 'int64_t' } },
		{ dump_nvtop: { type: 'int64_t' } },
		{ dump_npages: { type: 'pgcnt_t' } },
		{ dump_ksyms_size: { type: 'size_t' } },
		{ dump_ksyms_csize: { type: 'size_t' } },
		{ dump_fm_panic: { type: 'uint32_t' } },
		{ dump_uuid: { type: 'char[37]' } },
	];

	var types = {
		size_t: 'uint64_t',
		time_t: 'int64_t',
		offset_t: 'uint64_t',
		pgcnt_t: 'uint64_t'
	};

	for (t in types)
		parser.typedef(t, types[t]);

	parser.typedef('struct utsname', utsname);

	hdr = parser.readData(dumphdr, buffer, 0);

	if (hdr.dump_magic != constants.DUMP_MAGIC) {
		status('not a dump; magic mismatch (expected ' +
		    constants.DUMP_MAGIC + '; found ' + hdr.dump_magic + ')');
		return (false);
	}

	if (!(hdr.dump_flags & constants.DF_COMPLETE)) {
		status('not a complete dump');
		return (false);
	}

	if (!(hdr.dump_flags & constants.DF_COMPRESSED)) {
		status('dump is not compressed');
		return (false);
	}
	
	/*
	 * To hash a dump, we hash only the dump header.  This contains enough
	 * information (and in particular, time stamp, node name, and number
	 * of pages) that an md5 should be sufficiently unique.
	 */
	sum.update(util.inspect(hdr));

	return (true);
}

checkError = function (err)
{
	if (err)
		fatal(err.toString());
}

jobWait = function (client, jobid, cb)
{
	status('waiting for completion of job ' + jobid);
	var start = new Date().valueOf();

	var check = function () {
		client.job(jobid, function (err, job) {
			checkError(err);

			if (job.state == 'running' || job.state == 'queued') {
				again();
			} else if (job.state == 'done' &&
			    (job.stats.errors === 0 || (job.phases.length > 1 &&
			    job.stats.outputs == 1))) {
				status('job ' + jobid +  ' completed in ' +
				    hms(new Date().valueOf() - start));
				cb(job);
	 		} else {
				fatal('job ' + jobid + ' failed: ' +
				    util.inspect(job));
			}
		});
	};

	var again = function () {
		setTimeout(check, 250);
	};

	check();
};

jobOutput = function (client, cb)
{
	var fetchOutput = function (job, key) {
		client.get(key, function (err, stream, res) {
			checkError(err);

			var output = '';

			stream.on('data', function (data) {
				output += data;
			});

			stream.on('end', function () {
				cb(output);
			});
		});
	};

	return (function (job) {
		client.jobOutput(job.id, function (err, out) {
			checkError(err);
			out.on('key', function (k) { fetchOutput(job, k); });
		});
	});
}

jobOneKey = function (client, key, cmd, cb, preflight)
{
	var job = { phases: [ { exec: cmd, type: 'storage-map' } ] };

	if (preflight)
		preflight(job);

	client.createJob(job, function (err, id) {
		checkError(err);

		status('adding key to job ' + id);

		client.addJobKey(id, key, function (err) {
			checkError(err);

			client.endJob(id, function (err) {
				checkError(err);
				status('processing job ' + id);
				jobWait(client, id, cb);
			});
		});
	});
};

jobAllKeys = function (client, job, cb)
{
	/*
	 * To run a job on all keys, we push an initial object generation phase 
	 * (paradoxically of type 'reduce') that performs an mls and uses mcat
	 * to feed those objects as inputs to the next phase.
	 */
	var cmd = 'mls ' + thoth.path + ' | awk \'{ printf("' +
	    thoth.path + '/%s/info.json\\n", $1) }\' | xargs mcat';

	job.phases.unshift({ exec: cmd, type: 'reduce' });

	client.createJob(job, function (err, id) {
		checkError(err);

		status('created job ' + id);

		client.endJob(id, function (err) {
			checkError(err);
			jobWait(client, id, cb);
		});
	});
};

jobFromSpec = function (client, argv, opts, cb)
{
	/*
	 * Our job is going to be to all information for all specified dumps.
	 */
	var cmd = 'cat $MANTA_INPUT_FILE ';
	var illegal = undefined;
	var i;

	for (i = 0; i < argv.length; i++) {
		var filter = argv[i].split('=');

		cmd += ' | ';

		if (filter.length != 2) {
			if (!opts.aggregate)
				fatal('dump specification must be "prop=val"');
	
			if (i != argv.length - 1)
				fatal('aggregation property must be last');

			cmd += 'json ' + argv[i];
			break;
		}

		/*
		 * More one-off grossness:  to allow for easy stack matching,
		 * we always flatten the stack and delimit the frames with
		 * colons.
		 */
		if (filter[0] == 'stack')
			filter[0] = 'stack.join(":")';

		/*
		 * This is one million percent ghetto, but if we see a '*',
		 * we'll turn it into a proper regular expression.
		 */
		if (filter[1].indexOf('*') != -1) {
			illegal = filter[1].match(/([.+?^=!:${}()|[\]\/\\])/);

			if (illegal)
				break;

			cmd += 'json -c \'' + filter[0] + '.match(/^' +
			    filter[1].replace(/\*/g, '(.|\\n)*') + '$/)\'';
		} else if (filter[1] == 'undefined') {
			cmd += 'json -c \'!this.' + filter[0] + '\'';
		} else {
			illegal = filter[1].match(/["']/);

			if (illegal)
				break;

			cmd += 'json -c \'' + filter[0] + '=="' +
			    filter[1] + '"\'';
		}
	}

	if (opts.aggregate && i == argv.length)
		fatal('must supply an aggregation property');

	if (illegal) {
		fatal('"' + argv[i] + '" contains illegal ' +
		    'character \'' + illegal[0] +
		    '\' at index ' + illegal.index);
	}

	if (opts.fields) {
		var f;

		cmd += ' | json -a -d\\| ';

		for (i = 0; i < opts.fields.length; i++)
			cmd += opts.fields[i] + ' ';

		cmd += '| awk \'BEGIN{FS="|"} { printf("{"); ';

		for (i = 0; i < opts.fields.length; i++) {
			cmd += 'printf("\\"' + opts.fields[i] + '\\": ';
			cmd += '\\"%s\\"' + (i < opts.fields.length - 1 ?
			    ',' : '') + '", $' + (i + 1) + '); ';
		}

		cmd += '} END{if (NR == 1) { printf("}"); } }\' | json';
	}

	/*
	 * If we're aggregating, we want to generate JSON output.
	 */
	var aggregate = 'sort | uniq -c | sort -n | sed \'s/"/\\\\"/g\' | ' +
	    'awk \'BEGIN{printf("{");} ' +
	    '{ printf("%s\\"%s\\": %s", NR > 1 ? ",\\n" : "\\n", $2, $1)} ' +
	    'END{printf("}")}\' | json';

	job = { phases: [ { exec: cmd, type: 'storage-map' },
	    { exec: opts.aggregate ? aggregate : 'json -g',
	    type: 'reduce' } ] };

	jobAllKeys(client, job, jobOutput(client, function (output) {
		cb(output.length > 0 ? output : '[]');
	}))
}

processStack = function ()
{
	return ('mdb -e \'$c 0\' $MANTA_INPUT_FILE 2> /dev/null | ' +
	    'awk \'BEGIN{printf("\\t\\"stack\\": [ ")} ' +
	    '{printf("%s\\"%s\\"", NR > 1 ? ", " : "", $0)} ' +
	    'END{printf(" ],\\n")}\'');
}

processCore = function (client, stat, base, dump, cb)
{
	var elfdump = 'elfdump -n $MANTA_INPUT_FILE | ';
	var json = '/tmp/json.$$';
	var quotestr = 'sed \'s/"/\\\"/g\'';

	var dumpfield = function (f) {
		return (elfdump + 'awk \'{ if ($1 == "' + f + ':") ' +
		    '{ print $2; exit(0) } }\' | ' + quotestr);
	};

	var dumpline = function (f) {
		return (elfdump + 'awk \'{ if ($1 == "' + f + ':") { ' +
		    'print $0; exit(0); } }\' | cut -d: -f2 | ' +
		    'sed \'s/^[ ]*//g\' | ' + quotestr);
	};

	var echo = function (f) {
		return ('echo \'' + f + '\'');
	};

	var fields = {
		name: echo(base),
		dump: echo(dump),
		pid: dumpfield('pr_pid'),
		cmd: dumpline('pr_fname'),
		psargs: dumpline('pr_psargs'),
		platform: dumpfield('version'),
		node: dumpfield('nodename'),
		version: echo(thoth.version),
		time: { val: echo((stat.mtime.valueOf() / 1000) + '') }
	};

	var cmd = 'echo { > ' + json + '; ';

	for (f in fields) {
		if (fields[f] instanceof Object) {
			cmd += fields[f].val + '| awk \'{ printf("\\t\\"' + f +
			    '\\": %s,\\n", $0) }\' >> ' + json + ';'
			continue;
		}

		cmd += fields[f] + '| awk \'{ printf("\\t\\"' + f +
		    '\\": \\"%s\\",\\n", $0) }\' >> ' + json + ';'
	}

	cmd += processStack() + ' >> ' + json + '; ';
	cmd += 'echo \'\t"type": "core",\' >> ' + json + '; ';
	cmd += 'echo \'\t"properties": {}\' >> ' + json + '; ';
	cmd += 'echo } >> ' + json + '; ';
	cmd += 'mput -f ' + json + ' ' + base + '/info.json';

	job = { phases: [ { exec: cmd, type: 'storage-map' } ] };

	status('creating job to process ' + mod_path.basename(base));

	client.createJob(job, function (err, id) {
		checkError(err);

		status('adding key to job ' + id);

		client.addJobKey(id, dump, function (err) {
			checkError(err);
			status('processing ' + mod_path.basename(base));

			client.endJob(id, function (err) {
				checkError(err);
				jobWait(client, id, cb);
			});
		});
	});
};

var uncompressCore = function (client, stat, base, dump, cb)
{
	cmd = 'gunzip -cd $MANTA_INPUT_FILE > /var/tmp/gunzip.$$ ;'
	cmd += 'mput -f /var/tmp/gunzip.$$ ' + dump;

	status('creating job to uncompress ' + mod_path.basename(base));
	jobOneKey(client, dump + '.gz', cmd,
	    function () { processCore(client, stat, base, dump, cb); },
	    function (job) { job.phases[0].disk = 128; });
};

var progressBar = function (dump, stream, stat)
{
	if (!process.stderr.isTTY)
		return;

	var bar = new mod_manta.ProgressBar({
		filename: 'thoth: ' + mod_path.basename(dump),
		size: stat.size,
		nosize: false 
	});

	stream.on('data', function (data) {
		bar.advance(data.length);
	});

	stream.once('end', function () {
		bar.end();
	});
};

var putCore = function (client, file, stat, base, cb)
{
	/*
	 * We have the dump verified and we have the directory successfully
	 * created; time to actually upload the dump.
	 */
	var stream = mod_fs.createReadStream(file);
	var dump = base + '/' + mod_path.basename(file);
	var gzip = mod_zlib.createGzip();

	status('uploading ' + mod_path.basename(dump) + ' to ' +
	    mod_path.basename(base));

	progressBar(dump, stream, stat);

	pipe = stream.pipe(gzip);
	pipe.pause();

	var opts = {
		copies: 1,
		headers: { 'max-content-length': stat.size }
	};

	stream.on('open', function () {
		client.put(dump + '.gz', gzip, opts, function (err) {
			if (err)
				fatal(err.message);

			uncompressCore(client, stat, base, dump, cb);
		});
	});
};

var processCrash = function (client, stat, base, dump, cb)
{
	var mdb = function (cmd) {
		return ('mdb -e "' + cmd + '" $MANTA_INPUT_FILE ' +
		    '2> /dev/null | ');
	};

	var json = '/tmp/json.$$';

	var echo = function (f) {
		return ('echo \'' + f + '\'');
	};

	var dumpfield = function (f) {
		return (mdb('utsname::print') + 'grep "' + f + ' = " | ' +
		    'cut -d\\" -f2');
	};

	var fields = {
		name: echo(base),
		dump: echo(dump),
		platform: dumpfield('version'),
		node: dumpfield('nodename'),
		version: echo(thoth.version),
		time: { val: mdb('time/E') + 'tail -1 | awk \'{print $2}\'' }
	};

	var cmd = 'echo { > ' + json + '; ';

	for (f in fields) {
		if (fields[f] instanceof Object) {
			cmd += fields[f].val + '| awk \'{ printf("\\t\\"' + f +
			    '\\": %s,\\n", $0) }\' >> ' + json + ';'
			continue;
		}

		cmd += fields[f] + '| awk \'{ printf("\\t\\"' + f +
		    '\\": \\"%s\\",\\n", $0) }\' >> ' + json + ';'
	}

	cmd += processStack() + ' >> ' + json + '; ';
	cmd += 'echo \'\t"type": "crash",\' >> ' + json + '; ';
	cmd += 'echo \'\t"properties": {}\' >> ' + json + '; ';
	cmd += 'echo } >> ' + json + '; ';
	cmd += 'mput -f ' + json + ' ' + base + '/info.json';

	job = { phases: [ { exec: cmd, type: 'storage-map' } ] };

	status('creating job to process ' + mod_path.basename(base));

	client.createJob(job, function (err, id) {
		checkError(err);

		status('adding key to job ' + id);

		client.addJobKey(id, dump, function (err) {
			checkError(err);
			status('processing ' + mod_path.basename(base));

			client.endJob(id, function (err) {
				checkError(err);
				jobWait(client, id, cb);
			});
		});
	});
}

var uncompressCrash = function (client, stat, base, dump, cb)
{
	var vmcore = base + '/vmcore.0';
	var cmd = 'set -o errexit ;';
	cmd += 'dir=/var/tmp/savecore.$$ ;';
	cmd += 'mkdir $dir ; savecore -f $MANTA_INPUT_FILE -d $dir ; ';
	cmd += 'mput -f $dir/vmcore* ' + vmcore;

	status('creating job to savecore ' + mod_path.basename(base));
	jobOneKey(client, dump, cmd,
	    function () { processCrash(client, stat, base, vmcore, cb); },
	    function (job) {
		job.phases[0].disk = 256;
		job.phases[0].memory = 8192;
	    });
};

var putCrash = function (client, file, stat, base, cb)
{
	var stream = mod_fs.createReadStream(file);
	var dump = base + '/' + mod_path.basename(file);

	stream.pause();

	status('uploading ' + mod_path.basename(dump) + ' to ' +
	    mod_path.basename(base));

	progressBar(dump, stream, stat);

	var opts = {
		copies: 1,
		headers: { 'max-content-length': stat.size }
	};

	stream.on('open', function () {
		client.put(dump, stream, opts, function (err) {
			checkError(err);
			uncompressCrash(client, stat, base, dump, cb);
		});
	});
}

var openDump = function (name, cb, failed)
{
	var fd, file = { name: name };
	var stat;
	var sum = mod_crypto.createHash('md5');
	var path = [ thoth.path ], digest;

	try {
		fd = mod_fs.openSync(name, 'r');
	} catch (err) {
		if (!failed)
			fatal('couldn\'t open "' + name + '": ' + err);
		return (failed());
	}

	file.stat = mod_fs.fstatSync(fd);

	var done = function () {
		mod_fs.closeSync(fd);
		path.push(file.digest = sum.digest('hex'));
		file.base = path.join('/');
		cb(file);
	};

	if (isCore(fd, sum)) {
		file.type = 'core';
		done();
	} else if (isCrash(fd, sum)) {
		file.type = 'crash';
		done();
	} else {
		fatal('"' + name + '" is neither a core nor a crash dump');
	}
}

var infoGet = function (client, dump, cb)
{
	argToInfo(client, dump, function (object, err, stream, res) {
		checkError(err);

		var output = '';

		stream.on('data', function (data) {
			output += data;
		});

		stream.on('end', function () {
			cb(output);
		});
	});
}

handlers.upload = function (client, argv)
{
	put = {
		crash: putCrash,
		core: putCore 
	};

	var next = function () {
		if (argv.length == 1)
			process.exit(0);

		handlers.upload(client, argv.slice(1, argv.length));
	};

	openDump(argv[0], function (file) {
		status('creating ' + file.digest);

		client.mkdirp(file.base, function (err) {
			checkError(err);
			put[file.type](client,
			    file.name, file.stat, file.base, next);
		});
	});
}

handlers.ls = function (client, argv)
{
	status('creating job to list');

	var fmt = '%-16s %-5s %-19s %-16s %s';
	var fields = [ 'name', 'time', 'type', 'cmd', 'node', 'ticket' ];

	jobFromSpec(client, argv, { fields: fields }, function (output) {
		var dumps = JSON.parse(output);

		console.log(sprintf(fmt,
		    'DUMP', 'TYPE', 'TIME', 'NODE/CMD', 'TICKET'));

		dumps.sort(function (l, r) {
		    return (l.time < r.time ?  -1 : l.time > r.time ? 1 : 0);
		});

		for (i = 0; i < dumps.length; i++) {
			var dump = dumps[i];
			var t = new Date(dump.time * 1000);

			console.log(sprintf(fmt,
			    mod_path.basename(dump.name).substr(0, 16),
			    dump.type,
			    t.toISOString().substr(0, 19),
			    dump.type == 'core' ? dump.cmd : dump.node,
			    dump.ticket == '' ? '-' : dump.ticket));
		}

		process.exit(0);
	});
}

handlers.info = function (client, argv)
{
	var output = function (out) {
		console.log(out);
		process.exit(0);
	};

	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
		infoGet(client, argv[0], output);
	} else {
		jobFromSpec(client, argv, { aggregate: false }, output);
	}
}

handlers.debug = function (client, argv)
{
	var mlogin = mod_path.dirname(require.resolve('manta')) +
	    '/../bin/mlogin';

	var debug = function (out) {
		var dump = JSON.parse(out);

		if (dump instanceof Array) {
			if (dump.length > 1) {
				fatal('specification matches ' + dump.length +
				    ' dumps; cannot debug interactively');
			}

			dump = dump[0];
		}

		status('debugging ' +
		    mod_path.basename(mod_path.dirname(dump.dump)));

		var info = dump.name + '/info.json';

		var child = mod_child.spawn(mlogin, 
		    [ dump.dump, '-s', info,
		    '-c',
		    'export THOTH_INFO=/assets' + info + '; ' +
		    'echo "thoth: dump info in \\$THOTH_INFO";' +
		    'mdb $MANTA_INPUT_FILE' ],
		    { stdio: 'inherit' });

		child.on('close', function (code) {
			status('debugger exited with code ' + code);
			process.exit(code);
		});
	};

	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
		infoGet(client, argv[0], debug);
	} else {
		jobFromSpec(client, argv, { aggregate: false }, debug);
	}
}

handlers.object = function (client, argv)
{
	openDump(argv[0], function (file) {
		console.log(file.digest);
		process.exit(0);
	});
}

handlers.report = function (client, argv)
{
	jobFromSpec(client, argv, { aggregate: true }, function (output) {
		console.log(output);
		process.exit(0);
	});
};

var setProp = function (client, keys, prop, val, sysprop)
{
	var tmp = '/tmp/tmp.json';
	var json = '/tmp/new.json';
	var prefix = '', suffix = '';

	var cmd = 'cat > ' + tmp + ' <<EOF\n';

	if (!sysprop) {
		prefix = '{ "properties": ';
		suffix = '} ';
	}

	cmd += prefix + '{ "' + prop + '": ';
	cmd += JSON.stringify(val);

	cmd += '} ' + suffix + '\nEOF\n';

	cmd += 'cat $MANTA_INPUT_FILE ' + tmp + ' | json --deep-merge > ' +
	    json + ';';
	cmd += 'mput -f ' + json + ' $MANTA_INPUT_OBJECT'; 

	jobOneKey(client, keys, cmd, function () { process.exit(0) });
}

var unsetProp = function (client, keys, prop, sysprop)
{
	var json = '/tmp/new.json';
	var cmd = 'cat $MANTA_INPUT_FILE | json -e "this.' +
	    (sysprop ? '' : 'properties.') +
	    prop + '=undefined" > ' + json + '; ';
	cmd += 'mput -f ' + json + ' $MANTA_INPUT_OBJECT'; 

	jobOneKey(client, keys, cmd, function () { process.exit(0) });
}

var partialArgToInfo = function(client, arg, cb)
{
	var matches = [];

	client.ls(thoth.path, function (err, res) {
		checkError(err);

		res.on('directory', function (obj) {
			if (obj.name.indexOf(arg) == -1)
				return;

			matches.push(obj.name);
		});

		res.on('end', function () {
			if (matches.length == 0) {
				fatal('\'' + arg + '\' doesn\'t ' +
				    'match any dump');
			}

			if (matches.length > 1) {
				fatal('\'' + arg + '\' underspecified; ' +
				    '(matches ' + matches.length + ' dumps)');
			}

			argToInfo(client, matches[0], cb);
			return;
		});
	});
}

var argToInfo = function (client, arg, cb)
{
	var object = [ thoth.path, arg, 'info.json' ].join('/');

	client.get(object, function (err, stream, res) {
		if (err && err.code == 'ResourceNotFound') {
			openDump(arg, function (file) { 
				argToInfo(client, file.digest, cb);
				return;
			}, function () {
				if (arg.length < thoth.hashlen) {
					partialArgToInfo(client, arg, cb);
					return;
				}

				/*
				 * Our info doesn't exist and it doesn't
				 * correspond to a file on the local file
				 * system; to allow callers to differentiate
				 * between this case and any other error, we
				 * return with a special exit code (2).
				 */
				fatal(err.toString(), 2);
			});
			return;
		}

		cb(object, err, stream, res);
	});
}

var runAnalyzer = function (client, keys, analyzer)
{
	var sh = '/var/tmp/thoth.sh';
	var cmd = 'export THOTH_DUMP=$MANTA_INPUT_FILE; ';
	cmd += 'export THOTH_NAME=`basename $(dirname $MANTA_INPUT_FILE)`; ';
	cmd += 'if ( file $MANTA_INPUT_FILE | grep "core file" > /dev/null );'
	cmd += 'then THOTH_TYPE=core ; else THOTH_TYPE=crash ; fi ;';
	cmd += 'export THOTH_TYPE; ';

	cmd += 'export THOTH_INFO=/var/tmp/info.json ; ';
	cmd += 'THOTH_INFO_OBJECT=`dirname $MANTA_INPUT_OBJECT`/info.json ;'
	cmd += 'export THOTH_INFO_OBJECT ;';
	cmd += 'mget $THOTH_INFO_OBJECT > $THOTH_INFO ;';

	/*
	 * Now lay down our thoth support.  Yes, the escaping here is torture,
	 * due to the fact that we have a shell script embedded in a shell here
	 * document that is represented as a JavaScript string.  Blech!
	 */
	cmd += 'cat > ' + sh + ' <<EOF\n';
	cmd += 'set -o xtrace\n';
	cmd += 'set -o errexit\n';
	cmd += 'set -o pipefail\n\n';

	cmd += 'thoth_fatal()\n';
	cmd += '{\n';
	cmd += '	echo thoth: "\\$*" 1>&2\n';
	cmd += '	exit 1\n';
	cmd += '}\n\n';

	cmd += 'thoth_onexit()\n';
	cmd += '{\n';
	cmd += '	[[ \\$1 -ne 0 ]] || exit 0\n';
	cmd += '	thoth_fatal "error exit status \\$1"\n';
	cmd += '}\n\n';

	cmd += 'thoth_set()\n';
	cmd += '{\n';
	cmd += '	local prop=\\$1\n';
	cmd += '	local propfile=/tmp/thoth.prop\n';
	cmd += '	local propout=/tmp/thoth.out\n';
	cmd += '	if [[ "\\$#" -lt 1 ]]; then\n';
	cmd += '		thoth_fatal "failed to specify property"\n';
	cmd += '	fi\n\n';
	cmd += '	if [[ "\\$#" -eq 2 ]]; then\n';
	cmd += '		local propval="\\$2"\n';
	cmd += '	else\n';
	cmd += '		local propval=\\`cat | ';
	cmd += ' sed \'s/\\\\\\\\\\\\\\\\/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\/g\'';
	cmd += ' | ';
	cmd += ' sed \'s/\\"/\\\\\\\\\\\\\\\\"/g\' | ';
	cmd += ' sed \':a;N;\\$!ba;s/\\\\n/\\\\\\\\\\\\n/g\'\\`\n';
	cmd += '	fi\n\n';

	cmd += '	echo "{ \\"properties\\": { \\"\\$prop\\": ';
	cmd += '\\"\\$propval\\" } }" > \\$propfile\n';
	cmd += '	mget \\$THOTH_INFO_OBJECT > \\$THOTH_INFO\n';
	cmd += '	cat \\$THOTH_INFO \\$propfile | json --deep-merge ';
	cmd += ' > \\$propout\n';
	cmd += '	mput -f \\$propout \\$THOTH_INFO_OBJECT\n';
	cmd += '}\n\n';

	cmd += 'thoth_unset()\n';
	cmd += '{\n';
	cmd += '	local propout=/tmp/thoth.out\n';
	cmd += '	if [[ "\\$#" -lt 1 ]]; then\n';
	cmd += '		thoth_fatal "failed to specify property"\n';
	cmd += '	fi\n\n';
	cmd += '	mget \\$THOTH_INFO_OBJECT > \\$THOTH_INFO\n';
	cmd += '	cat \\$THOTH_INFO | json -e ';
	cmd += '"this.properties.\\$1=undefined" > \\$propout\n';
	cmd += '	mput -f \\$propout \\$THOTH_INFO_OBJECT\n';
	cmd += '}\n\n';

	cmd += 'thoth_ticket()\n';
	cmd += '{\n';
	cmd += '	local propfile=/tmp/thoth.prop\n';
	cmd += '	local propout=/tmp/thoth.out\n';
	cmd += '	if [[ "\\$#" -lt 1 ]]; then\n';
	cmd += '		thoth_fatal "failed to specify ticket"\n';
	cmd += '	fi\n\n';
	cmd += '	echo "{ \\"ticket\\": \\"\\$1\\" }" > \\$propfile\n';
	cmd += '	mget \\$THOTH_INFO_OBJECT > \\$THOTH_INFO\n';
	cmd += '	cat \\$THOTH_INFO \\$propfile | json --deep-merge ';
	cmd += ' > \\$propout\n';
	cmd += '	mput -f \\$propout \\$THOTH_INFO_OBJECT\n';
	cmd += '}\n\n';

	cmd += 'thoth_unticket()\n';
	cmd += '{\n';
	cmd += '	local propout=/tmp/thoth.out\n';
	cmd += '	mget \\$THOTH_INFO_OBJECT > \\$THOTH_INFO\n';
	cmd += '	cat \\$THOTH_INFO | json -e "this.ticket=undefined"';
	cmd += ' > \\$propout\n';
	cmd += '	mput -f \\$propout \\$THOTH_INFO_OBJECT\n';
	cmd += '}\n\n';

	cmd += 'EOF\n\n';

	cmd += 'cat /assets/' + analyzer + ' >> ' + sh + ' ; ';
	cmd += 'bash ' + sh + ' < /dev/null';

	var preflight = function (job) {
		job.phases[0].assets = [ analyzer ];
		job.phases.push({ exec: 'cat', type: 'reduce' });
	};

	var done = function (output) {
		console.log(output);
		process.exit(0);
	}

	jobOneKey(client, keys, cmd, jobOutput(client, done), preflight);
}

handlers.set = function (client, argv, sysprop)
{
	var i, val, prop, keys = [];

	function parseVal(val) {
		if (!val) {
			warn('value for \'' + prop + '\' not set ' +
			    'on command line; reading JSON from stdin');

			var maxval = 64 * 1024;
			var buf = new Buffer(maxval);
			var nbytes = mod_fs.readSync(0, buf, 0, maxval, 0);

			val = JSON.parse(buf.toString('utf8', 0, nbytes));
		} else {
			try {
				val = JSON.parse(val);
			} catch (err) {}
		}

		return (val);
	}

	if (argv[0].indexOf('=') == -1) {
		argToInfo(client, argv[0], function (path) {
			if (argv.length < 2)
				fatal('expected property to set');

			prop = argv[1];

			val = parseVal(argv.length >= 3 ? argv[2] : undefined);
			setProp(client, [ path ], prop, val, sysprop);
		});

		return;
	}

	for (i = 0; i < argv.length; i++) {
		if (argv[i].indexOf('=') != -1)
			continue;

		prop = argv[i];
		val = parseVal(i < argv.length - 1 ? argv[i + 1] : undefined);

		break;
	}

	argv.pop();

	if (i < argv.length)
		argv.pop();

	/*
	 * This is a little janky to do this in two passes.
	 */
	argv.push('name');

	jobFromSpec(client, argv, { aggregate: true }, function (output) {
		var dumps = JSON.parse(output);

		for (name in dumps)
			keys.push([ name, 'info.json' ].join('/'));

		setProp(client, keys, prop, val, sysprop);
	});
}

handlers.unset = function (client, argv, sysprop)
{
	var prop = argv.pop();
	var keys = [];

	if (!prop)
		fatal('expected a property to unset');

	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
		argToInfo(client, argv[0], function (path) {
			unsetProp(client, [ path ], prop, sysprop);
		});

		return;
	}

	/*
	 * This is a little janky to do this in two passes.
	 */
	argv.push('name');

	jobFromSpec(client, argv, { aggregate: true }, function (output) {
		dumps = JSON.parse(output);

		for (name in dumps)
			keys.push([ name, 'info.json' ].join('/'));

		unsetProp(client, keys, prop, sysprop);
	});
};

handlers.ticket = function (client, argv)
{
	if (argv.length < 2)
		fatal('need both dump specification and ticket');

	var ticket = argv.pop();
	argv.push('ticket');
	argv.push(ticket);

	return (handlers.set(client, argv, true));
};

handlers.unticket = function (client, argv)
{
	argv.push('ticket');

	return (handlers.unset(client, argv, true));
}

handlers.analyzer = function (client, argv)
{
	var remove = true;
	var analyzer, msg;

	if (argv.length != 1)
		fatal('analyzers must be named');

	analyzer = thoth.analyzers + '/' + argv[0];
	msg = 'analyzer \'' + argv[0] + '\'';

	warn('reading ' + msg + ' from stdin');

	/*
	 * We want to be sure to pause stdin after adding the 'data' listener
	 * to assure that this code works on v0.8 and v0.10+ alike.
	 */
	process.stdin.on('data', function () { remove = false; });
	process.stdin.pause();

	client.mkdirp(thoth.analyzers, function (err) {
		checkError(err);

		client.put(analyzer, process.stdin, function (err) {
			checkError(err);

			if (remove) {
				warn('removing ' + msg);
				client.unlink(analyzer, function (err) {
					checkError(err);
					warn('removed ' + msg);
					process.exit(0);
				});
			} else {
				warn('added ' + msg);
				process.exit(0);
			}
		});
	});
}

handlers.analyzers = function (client, argv)
{
	var analyzers = [], i;

	client.ls(thoth.analyzers, function (err, res) {
		checkError(err);

		res.on('object', function (obj) {
			analyzers.push(thoth.analyzers + '/' + obj.name);
		});

		res.on('error', function (err) {
			if (err.code == 'ResourceNotFound')
				process.exit(0);
		});
	
		res.on('end', function () {
			analyzers.sort();

			for (i = 0; i < analyzers.length; i++)
				console.log(analyzers[i]);

			process.exit(0);
		});
	});
};

handlers.analyze = function (client, argv)
{
	var analyzer = argv.pop();

	if (analyzer.indexOf('/') != 0)
		analyzer = thoth.analyzers + '/' + analyzer;

	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
		infoGet(client, argv[0], function (output) {
			var info = JSON.parse(output);

			runAnalyzer(client, [ info.dump ], analyzer);
		});

		return;
	}

	argv.push('dump');

	jobFromSpec(client, argv, { aggregate: true }, function (output) {
		var all = JSON.parse(output);
		var dumps = [];

		for (dump in all)
			dumps.push(dump);
	
		runAnalyzer(client, dumps, analyzer);
	});
};

handlers.logs = function (client, argv)
{
	var results = [];
	var outstanding = {};
	var machines = 1;

	var timePath = function (hours) {
		var t = new Date(new Date().valueOf() - (3600 * hours * 1000));

		return (sprintf("%02d/%02d/%02d",
		    t.getUTCMonth() + 1, t.getUTCDate(), t.getUTCHours()));
	};

	var descend = function(path, cb) {
		outstanding[path] = 1;

		var done = function () {
			if (--outstanding[path] == 0)
				cb();
		};

		client.ls(path, function (err, res) {
			res.on('error', done);

			res.on('directory', function (obj) {
				outstanding[path]++;
				descend(path + '/' + obj.name, done);
			});

			res.on('object', function (obj) {
				results.push(path + '/' + obj.name);
			});

			res.on('end', done);
		});
	};

	client.ls(thoth.logs, function (err, res) {
		var hour, i;

		checkError(err);

		var doneMachines = function () {
			if (--machines == 0) {
				results.sort();
				for (i = 0; i < results.length; i++)
					console.log(results[i]);
				process.exit(0);
			}
		}

		res.on('directory', function (obj) {
			for (hour = 0; hour <= 1; hour++) {
				machines++;
				descend([ thoth.logs, obj.name,
				    thoth.log, timePath(hour) ].join('/'),
				    doneMachines);
			}
		});

		res.on('end', doneMachines);
	});
}

var connect = function()
{
	var i, opts = {};
	var mvars = [ 'MANTA_URL', 'MANTA_USER', 'MANTA_KEY_ID' ];

	for (i = 0; i < mvars.length; i++) {
		if (!process.env[mvars[i]]) {
			fatal('expected ' + mvars[i] +
			    ' environment variable to be set');
		}
	}

	opts.log = mod_bunyan.createLogger({
		name: mod_path.basename(process.argv[1]),
		level: (process.env.LOG_LEVEL || 'info'),
		stream: process.stderr,
		serializers: mod_restify.bunyan.serializers
	});

	return (mod_manta.createBinClient(opts));
}

var main = function()
{
	var i, argv = process.argv;
	var client = undefined;

	if (argv.length < 3)
		usage('expected command');

	thoth.analyzers = thoth.path + '/' + thoth.analyzers;
	thoth.logs = thoth.path + '/' + thoth.logs;

	for (i = 0; i < thoth.cmds.length; i++) {
		if (argv[2] != thoth.cmds[i].token)
			continue;

		argv = argv.slice(3, argv.length);

		if (!thoth.cmds[i].disconnected)
			client = connect();

		handlers[thoth.cmds[i].token].call(this, client, argv);
		break;
	}

	if (i == thoth.cmds.length)
		usage('unrecognized command "' + argv[2] + '"');
};

main();

